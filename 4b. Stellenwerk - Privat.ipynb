{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5c0cf6",
   "metadata": {},
   "source": [
    "# Webscraper f√ºr die privaten Jobs auf www.stellenwerk-hamburg.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0905b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99867df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "289257cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.stellenwerk-hamburg.de/jobboerse/privat\"\n",
    "query = {\n",
    "    'keywords': '',\n",
    "    'offer_type': 'job_ad_private',\n",
    "    'job_category': 'All',\n",
    "    'employment_type': 'All',\n",
    "    'page': '0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b33bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ee31d",
   "metadata": {},
   "source": [
    "## Aufruf der Webseite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23ab1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(base_url, params = query, headers = my_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77f346a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stellenwerk-hamburg.de/jobboerse/privat?keywords=&offer_type=job_ad_private&job_category=All&employment_type=All&page=0\n"
     ]
    }
   ],
   "source": [
    "print(r.request.url) # aufgerufene URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed299034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "print(r.request.headers) # an den Webserver gesendete Anfragekopfezeile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dca152b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(r.status_code) # War der Webseitenaufruf erfolgreich?\n",
    "print(r.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5319c2a",
   "metadata": {},
   "source": [
    "## HTML-Code der Webseite speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ed87063",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be089ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379dff8",
   "metadata": {},
   "source": [
    "## Gesuchte Informationen aus dem HTML-Code auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8051937",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ads = bs.find('div', class_ = 'JobSearch-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd2585e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_links = job_ads.find_all('a', class_ = 'Link')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21674f",
   "metadata": {},
   "source": [
    "Anzahl an Elementen (hier: Links zu den Stellenanzeigen) in der Liste *job_links*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d325b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "faf0c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jobboerse/bares-fuer-rares-pers-assistenz-priv-tags-24-30-hw-1549-1936-eu-hamburg-211210-507691\n",
      "/jobboerse/hr-payroll-peronalabrechnung-duesseldorf-211210-507699\n",
      "/jobboerse/nachhilfe-englisch-latein-und-mathe-hamburg-211210-507542\n",
      "/jobboerse/persoenliche-assistentin-bei-den-landungsbruecken-hamburg-211210-507543\n",
      "/jobboerse/suche-eine-nachhilfe-fuer-statistik-ii-hamburg-211210-507632\n",
      "/jobboerse/teilnehmerinnen-fuer-online-studie-zu-gesundheitsrecherchen-gesucht-koeln-211210-507696\n",
      "/jobboerse/wir-suchen-eine-zuverlaessige-haushalts-fee-hamburg-211210-507574\n",
      "/jobboerse/freizeitbegleitung-rollstuhlfahrerin-alle-2wo-auf-rechnung-hamburg-211209-507425\n",
      "/jobboerse/suche-hilfe-garten-und-haushalt-hamburg-211209-507455\n",
      "/jobboerse/nachhilfe-statistik-hamburg-211208-507267\n",
      "/jobboerse/nette-familie-sucht-putzhilfe-bahrenfeld-gross-flottbek-hamburg-211208-507099\n",
      "/jobboerse/persoenliche-pflege-assistenz-hamburg-211208-507134\n",
      "/jobboerse/php-developer-mit-hang-zum-wassersport-als-co-founder-gesucht-hamburg-211208-507172\n",
      "/jobboerse/haushaltshilfe-naehe-hcu-gesucht-hamburg-211207-506943\n",
      "/jobboerse/kinderbetreuung-fuer-5-und-8-jaehrigen-hamburg-211207-506999\n",
      "/jobboerse/ko-therapeuten-fuer-verhaltenstherapeutisches-intensivprogramm-aba-avt-gesucht-hamburg-2\n",
      "/jobboerse/reinigungshilfe-fuer-nette-familie-st-pauli-gesucht-hamburg-st-pauli-211207-507061\n",
      "/jobboerse/vorstellungsgespraech-vorbereitung-hamburg-211207-507042\n",
      "/jobboerse/babysitter-gesucht-maedchen-9-berlin-211206-506820\n",
      "/jobboerse/betreuung-hamburg-211206-506757\n"
     ]
    }
   ],
   "source": [
    "for l in job_links:\n",
    "    print(l['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98a6635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for link in job_links:\n",
    "    link = 'https://www.stellenwerk-hamburg.de' + link['href']\n",
    "    rows.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a49680b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stellenwerk-hamburg.de/jobboerse/bares-fuer-rares-pers-assistenz-priv-tags-24-30-hw-1549-1936-eu-hamburg-211210-507691\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/hr-payroll-peronalabrechnung-duesseldorf-211210-507699\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/nachhilfe-englisch-latein-und-mathe-hamburg-211210-507542\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/persoenliche-assistentin-bei-den-landungsbruecken-hamburg-211210-507543\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/suche-eine-nachhilfe-fuer-statistik-ii-hamburg-211210-507632\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/teilnehmerinnen-fuer-online-studie-zu-gesundheitsrecherchen-gesucht-koeln-211210-507696\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/wir-suchen-eine-zuverlaessige-haushalts-fee-hamburg-211210-507574\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/freizeitbegleitung-rollstuhlfahrerin-alle-2wo-auf-rechnung-hamburg-211209-507425\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/suche-hilfe-garten-und-haushalt-hamburg-211209-507455\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/nachhilfe-statistik-hamburg-211208-507267\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/nette-familie-sucht-putzhilfe-bahrenfeld-gross-flottbek-hamburg-211208-507099\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/persoenliche-pflege-assistenz-hamburg-211208-507134\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/php-developer-mit-hang-zum-wassersport-als-co-founder-gesucht-hamburg-211208-507172\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/haushaltshilfe-naehe-hcu-gesucht-hamburg-211207-506943\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/kinderbetreuung-fuer-5-und-8-jaehrigen-hamburg-211207-506999\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/ko-therapeuten-fuer-verhaltenstherapeutisches-intensivprogramm-aba-avt-gesucht-hamburg-2\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/reinigungshilfe-fuer-nette-familie-st-pauli-gesucht-hamburg-st-pauli-211207-507061\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/vorstellungsgespraech-vorbereitung-hamburg-211207-507042\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/babysitter-gesucht-maedchen-9-berlin-211206-506820\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/betreuung-hamburg-211206-506757\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892d6d8",
   "metadata": {},
   "source": [
    "### Bl√§ttern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1473158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seite 1 von 7\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "pages = bs.find('span', class_ = 'Pagination-text').get_text()\n",
    "print(pages)\n",
    "print(type(pages)) # Abfrage des Datentyps; hier: string (Zeichenkette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3a35884",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_max = int(pages.split(' ')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16f51b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(page_max)\n",
    "print(type(page_max)) # Abfrage des Datentyps; hier: integer (ganzzahliger Wert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a968c",
   "metadata": {},
   "source": [
    "Nun kann diese Information genutzt werden, um zu bl√§ttern. Dazu wird eine *for*-Schleife in Kombination mit der Funktion `range()` verwendet. `range()` bestimmt, wie h√§ufig die Schleife durchlaufen wird. Hier setzen wir *page_max* ein und addieren eine Eins hinzu, da `range()` standardm√§√üig den Stoppwert nicht mit einschlie√üt (also nur bis *page_max* - 1 l√§uft). In jedem Schleifendurchlauf wird im *Query-String* der Wert f√ºr den Schl√ºssel *page* (s. oben unter Aufbau der URL des Stellenwerks) um eins erh√∂ht. Im ersten Durchlauf ist page=0, im zweiten page=1, im dritten page=2 usw. Alle Links zu den Stellenanzeigen, die auf einer Seite zu finden sind, werden dann extrahiert und zu der Liste *all_links* hinzugef√ºgt.<br>\n",
    "Nach jedem Schleifendurchlauf stoppen wir mit `time.sleep(1)` das Programm f√ºr 1 Sekunde, bevor wir die n√§chste Seite aufrufen. Andernfalls w√ºrden wir mit zu vielen Anfragen in kurzer Zeit eventuell den Server √ºberlasten. Dies w√ºrde schlimmstenfalls eine [Denial-of-Service-Attacke](https://www.bsi.bund.de/DE/Themen/Verbraucherinnen-und-Verbraucher/Cyber-Sicherheitslage/Methoden-der-Cyber-Kriminalitaet/DoS-Denial-of-Service/dos-denial-of-service_node.html) darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4c26ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda565d88f2f4f96a380d2a8aeec497f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_links = [] # Anlegen einer leeren Liste zur Aufnahme der Links\n",
    "for page in tqdm(range(page_max + 1)): # tqdm vor range erzeugt einen Fortschrittsbalken \n",
    "    query[\"page\"] = page # Seitenzahl wird in jedem Schleifendurchlauf um 1 erh√∂ht\n",
    "    r = requests.get(base_url, params = query) # Webseite aufrufen\n",
    "    html = r.text # HTML-Code der Webseite speichern\n",
    "    bs = BeautifulSoup(html, 'html.parser') # HTML-Code an BeautifulSoup √ºbergeben\n",
    "    job_ads = bs.find('div', class_ = 'JobSearch-content') # Element mit Links zu den Stellenanzeigen extrahieren\n",
    "    job_links = job_ads.find_all('a', class_ = 'Link') # aus dieser Spalte alle Links zu den Anzeigen extrahieren\n",
    "    for link in job_links: # Protokoll und Hostname jedem Link voranstellen\n",
    "        link = 'https://www.stellenwerk-hamburg.de' + link['href']\n",
    "        all_links.append(link) # Links der Liste all_links hinzuf√ºgen\n",
    "    time.sleep(1) # eine Sekunde Verz√∂gerung nach jedem Seitenaufruf (friendly scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9bd18",
   "metadata": {},
   "source": [
    "Wie viele Elemente hat die Liste *all_links* nach dem durch alle Seiten gebl√§ttert wurde? Diese Anzahl entspricht der Anzahl an Stellenangeboten zum Scraping-Zeitpunkt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95bdb082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0dbbb4",
   "metadata": {},
   "source": [
    "Nun liegt eine Liste mit allen Links zu den Stellenangeboten vor. Jetzt muss noch bestimmt werden, welche Informationen zu den jeweiligen Stellenangeboten extrahiert werden sollen. Dazu ruft man beispielhaft eine oder mehrere Stellenanzeigen aus der Liste *all_links* auf untersucht den HTML-Quellcode mit den Entwicklerwerkzeugen. So k√∂nnen alle HTML-Elemente identifiziert werden, in denen die Job-spezifischen Informationen zu finden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d591e0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.stellenwerk-hamburg.de/jobboerse/bares-fuer-rares-pers-assistenz-priv-tags-24-30-hw-1549-1936-eu-hamburg-211210-507691\"\n",
    "r = requests.get(url)\n",
    "html = r.text\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(r.status_code) # War der Webseitenaufruf erfolgreich?\n",
    "print(r.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97738b",
   "metadata": {},
   "source": [
    "### Allgemeine Informationen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0c54d",
   "metadata": {},
   "source": [
    "Allgemeinere Informationen wie Job-Bezeichnung, Datum und ID der Anzeige sowie der Anzeigetyp finden sich im oberen Bereich der Seite und lassen sich wie folgt aus dem Quellcode herauslesen.\n",
    "Die Informationen zu *ad_date*, *ad_id* und *ad_type* befinden sich in einem [*ul*-Tag](https://www.w3schools.com/tags/tag_ul.asp), mit dem ungeordnete Listen angelegt werden. Die Listeeintr√§ge starten jeweils mit einem *li*-Tag. Da *ad_date* die erste *li*-Instanz ist, kann diese Information einfach mit `.find()` entnommen werden. Der Eintrag enth√§lt die Zeichenkette \"Online seit DD.MM.YYYY\". Diese wird mit Hilfe der Methode `.split()` am Leerzeichen (' ') in ihre Komponenten zerlegt und dann das dritte Element (DD.MM.YYYY) extrahiert.\n",
    "Bei *ad_id* und *ad_type* kommt die Funktion `.select()` von *BeautifulSoup* zum Einsatz, der man einen [CSS-Selektor](https://www.w3schools.com/cssref/css_selectors.asp) √ºbergeben kann. Die Informationen\n",
    "Rechtsklick Kontextmen√º "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efd27370",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = bs.find('h1', class_ = 'JobHead-title').get_text()\n",
    "ad_date = bs.find('li', class_ = 'JobHead-additionalInfoItem').get_text().split(' ')[2]\n",
    "ad_id = bs.select('li.JobHead-additionalInfoItem:nth-child(2)')[0].get_text()\n",
    "ad_type = bs.select('li.JobHead-additionalInfoItem:nth-child(3)')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a6f49",
   "metadata": {},
   "source": [
    "### Anzeigendaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d8bca",
   "metadata": {},
   "source": [
    "Informationen wie Art und Zeitraum der Besch√§ftigung, Verg√ºtung sowie Bewerbungslink oder Bewerbungs-E-Mail (es gibt nur eins von beiden) finden sich im unteren Drittel der Stellenanzeigen.<br>\n",
    "Hier werden das erste Mal mit [*try* und *except*](https://www.w3schools.com/python/python_try_except.asp) Ausnahmen behandelt:<br>\n",
    "+ Nicht jede Stellenanzeige weist eine Verg√ºtung aus\n",
    "+ Wenn ein Bewerbunslink angegeben wurde, fehlt die Bewerbungs-E-Mail und vice versa, da es auf der Webseite des Stellenwerks sich ausschlie√üende Alternativen sind.\n",
    "\n",
    "Ein Exraktionsversuch bei fehlenden Informationen w√ºrde zu einer Fehlermeldung und zu einem Programmabbruch f√ºhren. F√ºr so einen Fall wird im *except*-Block explizit der Wert *None* vergeben. Durch diese Konstruktion wird ein Programmabbruch verhindert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76b8c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type = bs.find(string = \"Art der Besch√§ftigung\").find_next('dd').get_text() # Suche nach dem Tag mit Inhalt \"Art der Besch√§ftigung\", dann das folgende dd-Tag w√§hlen\n",
    "job_duration = bs.find(string = \"Zeitraum der Besch√§ftigung\").find_next('dd').get_text()\n",
    "try:\n",
    "    job_wage = bs.find(string = \"Verg√ºtung\").find_next('dd').get_text()\n",
    "except:\n",
    "    job_wage = None\n",
    "try:\n",
    "    app_link = bs.find(string = \"Bewerbungslink\").find_next('dd').find_next('a', class_ = 'Link')['href']\n",
    "except:\n",
    "    app_link = None\n",
    "try:\n",
    "    app_email = bs.find(string = \"Bewerbungs-E-Mail\").find_next('a', class_ = 'IconText-mail IconText')['href']\n",
    "except:\n",
    "    app_email = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9bf3d",
   "metadata": {},
   "source": [
    "### Beschreibung und Anforderungsprofil der Stelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e152b",
   "metadata": {},
   "source": [
    "Die Beschreibung der Stelle und das Anforderungsprofil sind die zentralen stellenbezogenen Informationen und finden sich in zwei seperaten Textfeldern im mittleren Teil der Seite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "853d6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descrip = bs.find_all('div', class_ = 'RichText')[0].get_text()\n",
    "job_profile = bs.find_all('div', class_ = 'RichText')[1].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba6967",
   "metadata": {},
   "source": [
    "### Firmenkontaktdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d31ea",
   "metadata": {},
   "source": [
    "Die Firmenkontaktdaten stehen am Ende der Seite und beinhalten Informationen wie Firmenname, Adresse und Kontaktperson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17b60652",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = bs.find(string = \"Standort\").find_all_next('dd', limit = 2)\n",
    "location = loc[0].get_text()+ \", \" + loc[1].get_text()\n",
    "contact = bs.find(string = \"Kontaktperson\").find_next('dd').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa9efb",
   "metadata": {},
   "source": [
    "## Schleife √ºber alle Stellenanzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d5d7b",
   "metadata": {},
   "source": [
    "Nun wird alles kombiniert. Die Informationen (allgemeine Informationen, Anzeigendaten, Beschreibung und Anforderungsprofil der Stelle, Firmeninformationen) m√ºssen nun f√ºr *alle* Stellenanzeigen extrahiert werden. Mit Hilfe einer *for*-Schleife werden daf√ºr alle Links aus *all_links* nacheinander aufgerufen, der jeweilige HTML-Quellcode abgerufen, aus diesem die relevanten Informationen zu jeder Stellenanzeige extrahiert und in einem Python-Dictionary (Schl√ºssel-Wert-Paare) names *row* gespeichert. Diese Dictionaries werden dann ein eine Liste namens *rows* √ºbertragen, d.h. die Liste hat so viele Elemente in Form von Dictionaries, wie es Stellenanzeigen gibt. Die *try*-und-*except*-Bl√∂cke verhindern den Programm-Abbruch falls in einzelnen Stellenanzeigen manche Informationen nicht vorhanden sind und somit nicht ausgelesen werden k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a2e6ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1c1dfae57d4b0ba10ffacb8f908f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for link in tqdm(all_links): # tqdm vor der iterierbaren Liste 'all_links' erzeugt einen Fortschrittsbalken \n",
    "    r = requests.get(link, headers = my_headers) # Webseite aufrufen\n",
    "    html = r.text # HTML-Code der Webseite speichern\n",
    "    bs = BeautifulSoup(html, 'html.parser') # HTML-Code an BeautifulSoup √ºbergeben\n",
    "    try: # alle ben√∂tigen Informationen aus dem HTML-Code extrahieren\n",
    "        job_title = bs.find('h1', class_ = 'JobHead-title').get_text()\n",
    "    except:\n",
    "        job_title = None\n",
    "    try:\n",
    "        ad_date = bs.find('li', class_ = 'JobHead-additionalInfoItem').get_text().split(' ')[2]\n",
    "    except:\n",
    "        ad_date = None\n",
    "    try:    \n",
    "        ad_id = bs.select('li.JobHead-additionalInfoItem:nth-child(2)')[0].get_text()\n",
    "    except:\n",
    "        ad_id = None\n",
    "    try:\n",
    "        ad_type = bs.select('li.JobHead-additionalInfoItem:nth-child(3)')[0].get_text()\n",
    "    except:\n",
    "        ad_type = None\n",
    "    try:\n",
    "        job_type = bs.find(string = \"Art der Besch√§ftigung\").find_next('dd').get_text() # Suche nach dem Tag mit Inhalt \"Art der Besch√§ftigung\", dann das folgende dd-Tag w√§hlen\n",
    "    except:\n",
    "        job_type = None\n",
    "    try:\n",
    "        job_duration = bs.find(string = \"Zeitraum der Besch√§ftigung\").find_next('dd').get_text()\n",
    "    except:\n",
    "        job_duration = None\n",
    "    try:\n",
    "        job_wage = bs.find(string = \"Verg√ºtung\").find_next('dd').get_text()\n",
    "    except:\n",
    "        job_wage = None\n",
    "    try:\n",
    "        app_link = bs.find(string = \"Bewerbungslink\").find_next('dd').find_next('a', class_ = 'Link')['href']\n",
    "    except:\n",
    "        app_link = None\n",
    "    try:\n",
    "        app_email = bs.find(string = \"Bewerbungs-E-Mail\").find_next('a', class_ = 'IconText-mail IconText')['href']\n",
    "    except:\n",
    "        app_email = None\n",
    "    try:\n",
    "        loc = bs.find(string = \"Standort\").find_all_next('dd', limit = 2)\n",
    "        location = loc[0].get_text()+ \", \" + loc[1].get_text()\n",
    "    except:\n",
    "        loc, location = None, None\n",
    "    try:\n",
    "        contact = bs.find(string = \"Kontaktperson\").find_next('dd').get_text()\n",
    "    except:\n",
    "        contact = None\n",
    "    try:\n",
    "        job_descrip = bs.find_all('div', class_ = 'RichText')[0].get_text()\n",
    "    except:\n",
    "        job_descrip = None\n",
    "    try:\n",
    "        job_profile = bs.find_all('div', class_ = 'RichText')[1].get_text()\n",
    "    except:\n",
    "        job_profile = None\n",
    "    row = { # alle extrahierten Informationen in ein Dictionary schreiben\n",
    "    'job_title': job_title,\n",
    "    'ad_date': ad_date,\n",
    "    'ad_id': ad_id,\n",
    "    'ad_type': ad_type,\n",
    "    'job_type': job_type,\n",
    "    'job_duration': job_duration,\n",
    "    'job_wage': job_wage,\n",
    "    'app_link': app_link,\n",
    "    'app_email': app_email,\n",
    "    'location': location,\n",
    "    'contact': contact,\n",
    "    'job_descrip': job_descrip,\n",
    "    'job_profile': job_profile,\n",
    "    'link': link\n",
    "    }\n",
    "    rows.append(row) # Dictionary names row wird der Liste namens rows angeh√§ngt\n",
    "    time.sleep(1) # eine Sekunde Verz√∂gerung nach jedem Seitenaufruf (friendly scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bef10",
   "metadata": {},
   "source": [
    "## Extrahierte Daten in CSV-Datei schreiben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4b148",
   "metadata": {},
   "source": [
    "Die extrahierten Daten, die in der Liste *rows* gespeichert sind, werden abschlie√üend in eine rechteckige Datenmatrix geschrieben. Jede Stellenanzeige (Merkmalstr√§ger) bildet eine Zeile. Die Merkmale der Stellenanzeigen bilden die Spalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8b5f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'daten/job_ads_privat.csv'\n",
    "with open(file, mode = 'w', encoding = 'utf-8', newline = '') as f:\n",
    "    col_names = ['job_title', 'ad_date', 'ad_id', 'ad_type', 'job_type', 'job_duration', 'job_wage', 'app_link', 'app_email', 'location', 'contact', 'job_descrip', 'job_profile', 'link']\n",
    "    writer = csv.DictWriter(f, fieldnames = col_names)\n",
    "    writer.writeheader()\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe5a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
