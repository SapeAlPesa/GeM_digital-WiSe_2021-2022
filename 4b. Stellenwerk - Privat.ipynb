{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5c0cf6",
   "metadata": {},
   "source": [
    "# Webscraper für die privaten Jobs auf www.stellenwerk-hamburg.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0905b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99867df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "289257cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.stellenwerk-hamburg.de/jobboerse/privat\"\n",
    "query = {\n",
    "    'keywords': '',\n",
    "    'offer_type': 'job_ad_private',\n",
    "    'job_category': 'All',\n",
    "    'employment_type': 'All',\n",
    "    'page': '0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b33bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ee31d",
   "metadata": {},
   "source": [
    "## Aufruf der Webseite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23ab1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(base_url, params = query, headers = my_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77f346a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stellenwerk-hamburg.de/jobboerse/privat?keywords=&offer_type=job_ad_private&job_category=All&employment_type=All&page=0\n"
     ]
    }
   ],
   "source": [
    "print(r.request.url) # aufgerufene URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed299034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "print(r.request.headers) # an den Webserver gesendete Anfragekopfezeile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dca152b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(r.status_code) # War der Webseitenaufruf erfolgreich?\n",
    "print(r.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5319c2a",
   "metadata": {},
   "source": [
    "## HTML-Code der Webseite speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ed87063",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be089ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379dff8",
   "metadata": {},
   "source": [
    "## Gesuchte Informationen aus dem HTML-Code auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8051937",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ads = bs.find('div', class_ = 'JobSearch-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd2585e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_links = job_ads.find_all('a', class_ = 'Link')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21674f",
   "metadata": {},
   "source": [
    "Anzahl an Elementen (hier: Links zu den Stellenanzeigen) in der Liste *job_links*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d325b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "faf0c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jobboerse/bares-fuer-rares-pers-assistenz-priv-tags-24-30-hw-1549-1936-eu-hamburg-211210-507691\n",
      "/jobboerse/hr-payroll-peronalabrechnung-duesseldorf-211210-507699\n",
      "/jobboerse/nachhilfe-englisch-latein-und-mathe-hamburg-211210-507542\n",
      "/jobboerse/persoenliche-assistentin-bei-den-landungsbruecken-hamburg-211210-507543\n",
      "/jobboerse/suche-eine-nachhilfe-fuer-statistik-ii-hamburg-211210-507632\n",
      "/jobboerse/teilnehmerinnen-fuer-online-studie-zu-gesundheitsrecherchen-gesucht-koeln-211210-507696\n",
      "/jobboerse/wir-suchen-eine-zuverlaessige-haushalts-fee-hamburg-211210-507574\n",
      "/jobboerse/freizeitbegleitung-rollstuhlfahrerin-alle-2wo-auf-rechnung-hamburg-211209-507425\n",
      "/jobboerse/suche-hilfe-garten-und-haushalt-hamburg-211209-507455\n",
      "/jobboerse/nachhilfe-statistik-hamburg-211208-507267\n",
      "/jobboerse/nette-familie-sucht-putzhilfe-bahrenfeld-gross-flottbek-hamburg-211208-507099\n",
      "/jobboerse/persoenliche-pflege-assistenz-hamburg-211208-507134\n",
      "/jobboerse/php-developer-mit-hang-zum-wassersport-als-co-founder-gesucht-hamburg-211208-507172\n",
      "/jobboerse/haushaltshilfe-naehe-hcu-gesucht-hamburg-211207-506943\n",
      "/jobboerse/kinderbetreuung-fuer-5-und-8-jaehrigen-hamburg-211207-506999\n",
      "/jobboerse/ko-therapeuten-fuer-verhaltenstherapeutisches-intensivprogramm-aba-avt-gesucht-hamburg-2\n",
      "/jobboerse/reinigungshilfe-fuer-nette-familie-st-pauli-gesucht-hamburg-st-pauli-211207-507061\n",
      "/jobboerse/vorstellungsgespraech-vorbereitung-hamburg-211207-507042\n",
      "/jobboerse/babysitter-gesucht-maedchen-9-berlin-211206-506820\n",
      "/jobboerse/betreuung-hamburg-211206-506757\n"
     ]
    }
   ],
   "source": [
    "for l in job_links:\n",
    "    print(l['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98a6635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for link in job_links:\n",
    "    link = 'https://www.stellenwerk-hamburg.de' + link['href']\n",
    "    rows.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a49680b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stellenwerk-hamburg.de/jobboerse/bares-fuer-rares-pers-assistenz-priv-tags-24-30-hw-1549-1936-eu-hamburg-211210-507691\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/hr-payroll-peronalabrechnung-duesseldorf-211210-507699\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/nachhilfe-englisch-latein-und-mathe-hamburg-211210-507542\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/persoenliche-assistentin-bei-den-landungsbruecken-hamburg-211210-507543\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/suche-eine-nachhilfe-fuer-statistik-ii-hamburg-211210-507632\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/teilnehmerinnen-fuer-online-studie-zu-gesundheitsrecherchen-gesucht-koeln-211210-507696\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/wir-suchen-eine-zuverlaessige-haushalts-fee-hamburg-211210-507574\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/freizeitbegleitung-rollstuhlfahrerin-alle-2wo-auf-rechnung-hamburg-211209-507425\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/suche-hilfe-garten-und-haushalt-hamburg-211209-507455\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/nachhilfe-statistik-hamburg-211208-507267\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/nette-familie-sucht-putzhilfe-bahrenfeld-gross-flottbek-hamburg-211208-507099\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/persoenliche-pflege-assistenz-hamburg-211208-507134\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/php-developer-mit-hang-zum-wassersport-als-co-founder-gesucht-hamburg-211208-507172\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/haushaltshilfe-naehe-hcu-gesucht-hamburg-211207-506943\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/kinderbetreuung-fuer-5-und-8-jaehrigen-hamburg-211207-506999\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/ko-therapeuten-fuer-verhaltenstherapeutisches-intensivprogramm-aba-avt-gesucht-hamburg-2\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/reinigungshilfe-fuer-nette-familie-st-pauli-gesucht-hamburg-st-pauli-211207-507061\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/vorstellungsgespraech-vorbereitung-hamburg-211207-507042\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/babysitter-gesucht-maedchen-9-berlin-211206-506820\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/betreuung-hamburg-211206-506757\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892d6d8",
   "metadata": {},
   "source": [
    "### Blättern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1473158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seite 1 von 7\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "pages = bs.find('span', class_ = 'Pagination-text').get_text()\n",
    "print(pages)\n",
    "print(type(pages)) # Abfrage des Datentyps; hier: string (Zeichenkette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3a35884",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_max = int(pages.split(' ')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16f51b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(page_max)\n",
    "print(type(page_max)) # Abfrage des Datentyps; hier: integer (ganzzahliger Wert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a968c",
   "metadata": {},
   "source": [
    "Nun kann diese Information genutzt werden, um zu blättern. Dazu wird eine *for*-Schleife in Kombination mit der Funktion `range()` verwendet. `range()` bestimmt, wie häufig die Schleife durchlaufen wird. Hier setzen wir *page_max* ein und addieren eine Eins hinzu, da `range()` standardmäßig den Stoppwert nicht mit einschließt (also nur bis *page_max* - 1 läuft). In jedem Schleifendurchlauf wird im *Query-String* der Wert für den Schlüssel *page* (s. oben unter Aufbau der URL des Stellenwerks) um eins erhöht. Im ersten Durchlauf ist page=0, im zweiten page=1, im dritten page=2 usw. Alle Links zu den Stellenanzeigen, die auf einer Seite zu finden sind, werden dann extrahiert und zu der Liste *all_links* hinzugefügt.<br>\n",
    "Nach jedem Schleifendurchlauf stoppen wir mit `time.sleep(1)` das Programm für 1 Sekunde, bevor wir die nächste Seite aufrufen. Andernfalls würden wir mit zu vielen Anfragen in kurzer Zeit eventuell den Server überlasten. Dies würde schlimmstenfalls eine [Denial-of-Service-Attacke](https://www.bsi.bund.de/DE/Themen/Verbraucherinnen-und-Verbraucher/Cyber-Sicherheitslage/Methoden-der-Cyber-Kriminalitaet/DoS-Denial-of-Service/dos-denial-of-service_node.html) darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4c26ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda565d88f2f4f96a380d2a8aeec497f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_links = [] # Anlegen einer leeren Liste zur Aufnahme der Links\n",
    "for page in tqdm(range(page_max + 1)): # tqdm vor range erzeugt einen Fortschrittsbalken \n",
    "    query[\"page\"] = page # Seitenzahl wird in jedem Schleifendurchlauf um 1 erhöht\n",
    "    r = requests.get(base_url, params = query) # Webseite aufrufen\n",
    "    html = r.text # HTML-Code der Webseite speichern\n",
    "    bs = BeautifulSoup(html, 'html.parser') # HTML-Code an BeautifulSoup übergeben\n",
    "    job_ads = bs.find('div', class_ = 'JobSearch-content') # Element mit Links zu den Stellenanzeigen extrahieren\n",
    "    job_links = job_ads.find_all('a', class_ = 'Link') # aus dieser Spalte alle Links zu den Anzeigen extrahieren\n",
    "    for link in job_links: # Protokoll und Hostname jedem Link voranstellen\n",
    "        link = 'https://www.stellenwerk-hamburg.de' + link['href']\n",
    "        all_links.append(link) # Links der Liste all_links hinzufügen\n",
    "    time.sleep(1) # eine Sekunde Verzögerung nach jedem Seitenaufruf (friendly scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9bd18",
   "metadata": {},
   "source": [
    "Wie viele Elemente hat die Liste *all_links* nach dem durch alle Seiten geblättert wurde? Diese Anzahl entspricht der Anzahl an Stellenangeboten zum Scraping-Zeitpunkt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95bdb082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0dbbb4",
   "metadata": {},
   "source": [
    "Nun liegt eine Liste mit allen Links zu den Stellenangeboten vor. Jetzt muss noch bestimmt werden, welche Informationen zu den jeweiligen Stellenangeboten extrahiert werden sollen. Dazu ruft man beispielhaft eine oder mehrere Stellenanzeigen aus der Liste *all_links* auf untersucht den HTML-Quellcode mit den Entwicklerwerkzeugen. So können alle HTML-Elemente identifiziert werden, in denen die Job-spezifischen Informationen zu finden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d591e0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.stellenwerk-hamburg.de/jobboerse/bares-fuer-rares-pers-assistenz-priv-tags-24-30-hw-1549-1936-eu-hamburg-211210-507691\"\n",
    "r = requests.get(url)\n",
    "html = r.text\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(r.status_code) # War der Webseitenaufruf erfolgreich?\n",
    "print(r.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97738b",
   "metadata": {},
   "source": [
    "### Allgemeine Informationen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0c54d",
   "metadata": {},
   "source": [
    "Allgemeinere Informationen wie Job-Bezeichnung, Datum und ID der Anzeige sowie der Anzeigetyp finden sich im oberen Bereich der Seite und lassen sich wie folgt aus dem Quellcode herauslesen.\n",
    "Die Informationen zu *ad_date*, *ad_id* und *ad_type* befinden sich in einem [*ul*-Tag](https://www.w3schools.com/tags/tag_ul.asp), mit dem ungeordnete Listen angelegt werden. Die Listeeinträge starten jeweils mit einem *li*-Tag. Da *ad_date* die erste *li*-Instanz ist, kann diese Information einfach mit `.find()` entnommen werden. Der Eintrag enthält die Zeichenkette \"Online seit DD.MM.YYYY\". Diese wird mit Hilfe der Methode `.split()` am Leerzeichen (' ') in ihre Komponenten zerlegt und dann das dritte Element (DD.MM.YYYY) extrahiert.\n",
    "Bei *ad_id* und *ad_type* kommt die Funktion `.select()` von *BeautifulSoup* zum Einsatz, der man einen [CSS-Selektor](https://www.w3schools.com/cssref/css_selectors.asp) übergeben kann. Die Informationen\n",
    "Rechtsklick Kontextmenü "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efd27370",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = bs.find('h1', class_ = 'JobHead-title').get_text()\n",
    "ad_date = bs.find('li', class_ = 'JobHead-additionalInfoItem').get_text().split(' ')[2]\n",
    "ad_id = bs.select('li.JobHead-additionalInfoItem:nth-child(2)')[0].get_text()\n",
    "ad_type = bs.select('li.JobHead-additionalInfoItem:nth-child(3)')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a6f49",
   "metadata": {},
   "source": [
    "### Anzeigendaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d8bca",
   "metadata": {},
   "source": [
    "Informationen wie Art und Zeitraum der Beschäftigung, Vergütung sowie Bewerbungslink oder Bewerbungs-E-Mail (es gibt nur eins von beiden) finden sich im unteren Drittel der Stellenanzeigen.<br>\n",
    "Hier werden das erste Mal mit [*try* und *except*](https://www.w3schools.com/python/python_try_except.asp) Ausnahmen behandelt:<br>\n",
    "+ Nicht jede Stellenanzeige weist eine Vergütung aus\n",
    "+ Wenn ein Bewerbunslink angegeben wurde, fehlt die Bewerbungs-E-Mail und vice versa, da es auf der Webseite des Stellenwerks sich ausschließende Alternativen sind.\n",
    "\n",
    "Ein Exraktionsversuch bei fehlenden Informationen würde zu einer Fehlermeldung und zu einem Programmabbruch führen. Für so einen Fall wird im *except*-Block explizit der Wert *None* vergeben. Durch diese Konstruktion wird ein Programmabbruch verhindert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76b8c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type = bs.find(string = \"Art der Beschäftigung\").find_next('dd').get_text() # Suche nach dem Tag mit Inhalt \"Art der Beschäftigung\", dann das folgende dd-Tag wählen\n",
    "job_duration = bs.find(string = \"Zeitraum der Beschäftigung\").find_next('dd').get_text()\n",
    "try:\n",
    "    job_wage = bs.find(string = \"Vergütung\").find_next('dd').get_text()\n",
    "except:\n",
    "    job_wage = None\n",
    "try:\n",
    "    app_link = bs.find(string = \"Bewerbungslink\").find_next('dd').find_next('a', class_ = 'Link')['href']\n",
    "except:\n",
    "    app_link = None\n",
    "try:\n",
    "    app_email = bs.find(string = \"Bewerbungs-E-Mail\").find_next('a', class_ = 'IconText-mail IconText')['href']\n",
    "except:\n",
    "    app_email = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9bf3d",
   "metadata": {},
   "source": [
    "### Beschreibung und Anforderungsprofil der Stelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e152b",
   "metadata": {},
   "source": [
    "Die Beschreibung der Stelle und das Anforderungsprofil sind die zentralen stellenbezogenen Informationen und finden sich in zwei seperaten Textfeldern im mittleren Teil der Seite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "853d6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descrip = bs.find_all('div', class_ = 'RichText')[0].get_text()\n",
    "job_profile = bs.find_all('div', class_ = 'RichText')[1].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba6967",
   "metadata": {},
   "source": [
    "### Firmenkontaktdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d31ea",
   "metadata": {},
   "source": [
    "Die Firmenkontaktdaten stehen am Ende der Seite und beinhalten Informationen wie Firmenname, Adresse und Kontaktperson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17b60652",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = bs.find(string = \"Standort\").find_all_next('dd', limit = 2)\n",
    "location = loc[0].get_text()+ \", \" + loc[1].get_text()\n",
    "contact = bs.find(string = \"Kontaktperson\").find_next('dd').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa9efb",
   "metadata": {},
   "source": [
    "## Schleife über alle Stellenanzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d5d7b",
   "metadata": {},
   "source": [
    "Nun wird alles kombiniert. Die Informationen (allgemeine Informationen, Anzeigendaten, Beschreibung und Anforderungsprofil der Stelle, Firmeninformationen) müssen nun für *alle* Stellenanzeigen extrahiert werden. Mit Hilfe einer *for*-Schleife werden dafür alle Links aus *all_links* nacheinander aufgerufen, der jeweilige HTML-Quellcode abgerufen, aus diesem die relevanten Informationen zu jeder Stellenanzeige extrahiert und in einem Python-Dictionary (Schlüssel-Wert-Paare) names *row* gespeichert. Diese Dictionaries werden dann ein eine Liste namens *rows* übertragen, d.h. die Liste hat so viele Elemente in Form von Dictionaries, wie es Stellenanzeigen gibt. Die *try*-und-*except*-Blöcke verhindern den Programm-Abbruch falls in einzelnen Stellenanzeigen manche Informationen nicht vorhanden sind und somit nicht ausgelesen werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a2e6ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1c1dfae57d4b0ba10ffacb8f908f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for link in tqdm(all_links): # tqdm vor der iterierbaren Liste 'all_links' erzeugt einen Fortschrittsbalken \n",
    "    r = requests.get(link, headers = my_headers) # Webseite aufrufen\n",
    "    html = r.text # HTML-Code der Webseite speichern\n",
    "    bs = BeautifulSoup(html, 'html.parser') # HTML-Code an BeautifulSoup übergeben\n",
    "    try: # alle benötigen Informationen aus dem HTML-Code extrahieren\n",
    "        job_title = bs.find('h1', class_ = 'JobHead-title').get_text()\n",
    "    except:\n",
    "        job_title = None\n",
    "    try:\n",
    "        ad_date = bs.find('li', class_ = 'JobHead-additionalInfoItem').get_text().split(' ')[2]\n",
    "    except:\n",
    "        ad_date = None\n",
    "    try:    \n",
    "        ad_id = bs.select('li.JobHead-additionalInfoItem:nth-child(2)')[0].get_text()\n",
    "    except:\n",
    "        ad_id = None\n",
    "    try:\n",
    "        ad_type = bs.select('li.JobHead-additionalInfoItem:nth-child(3)')[0].get_text()\n",
    "    except:\n",
    "        ad_type = None\n",
    "    try:\n",
    "        job_type = bs.find(string = \"Art der Beschäftigung\").find_next('dd').get_text() # Suche nach dem Tag mit Inhalt \"Art der Beschäftigung\", dann das folgende dd-Tag wählen\n",
    "    except:\n",
    "        job_type = None\n",
    "    try:\n",
    "        job_duration = bs.find(string = \"Zeitraum der Beschäftigung\").find_next('dd').get_text()\n",
    "    except:\n",
    "        job_duration = None\n",
    "    try:\n",
    "        job_wage = bs.find(string = \"Vergütung\").find_next('dd').get_text()\n",
    "    except:\n",
    "        job_wage = None\n",
    "    try:\n",
    "        app_link = bs.find(string = \"Bewerbungslink\").find_next('dd').find_next('a', class_ = 'Link')['href']\n",
    "    except:\n",
    "        app_link = None\n",
    "    try:\n",
    "        app_email = bs.find(string = \"Bewerbungs-E-Mail\").find_next('a', class_ = 'IconText-mail IconText')['href']\n",
    "    except:\n",
    "        app_email = None\n",
    "    try:\n",
    "        loc = bs.find(string = \"Standort\").find_all_next('dd', limit = 2)\n",
    "        location = loc[0].get_text()+ \", \" + loc[1].get_text()\n",
    "    except:\n",
    "        loc, location = None, None\n",
    "    try:\n",
    "        contact = bs.find(string = \"Kontaktperson\").find_next('dd').get_text()\n",
    "    except:\n",
    "        contact = None\n",
    "    try:\n",
    "        job_descrip = bs.find_all('div', class_ = 'RichText')[0].get_text()\n",
    "    except:\n",
    "        job_descrip = None\n",
    "    try:\n",
    "        job_profile = bs.find_all('div', class_ = 'RichText')[1].get_text()\n",
    "    except:\n",
    "        job_profile = None\n",
    "    row = { # alle extrahierten Informationen in ein Dictionary schreiben\n",
    "    'job_title': job_title,\n",
    "    'ad_date': ad_date,\n",
    "    'ad_id': ad_id,\n",
    "    'ad_type': ad_type,\n",
    "    'job_type': job_type,\n",
    "    'job_duration': job_duration,\n",
    "    'job_wage': job_wage,\n",
    "    'app_link': app_link,\n",
    "    'app_email': app_email,\n",
    "    'location': location,\n",
    "    'contact': contact,\n",
    "    'job_descrip': job_descrip,\n",
    "    'job_profile': job_profile,\n",
    "    'link': link\n",
    "    }\n",
    "    rows.append(row) # Dictionary names row wird der Liste namens rows angehängt\n",
    "    time.sleep(1) # eine Sekunde Verzögerung nach jedem Seitenaufruf (friendly scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bef10",
   "metadata": {},
   "source": [
    "## Extrahierte Daten in CSV-Datei schreiben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4b148",
   "metadata": {},
   "source": [
    "Die extrahierten Daten, die in der Liste *rows* gespeichert sind, werden abschließend in eine rechteckige Datenmatrix geschrieben. Jede Stellenanzeige (Merkmalsträger) bildet eine Zeile. Die Merkmale der Stellenanzeigen bilden die Spalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8b5f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'daten/job_ads_privat.csv'\n",
    "with open(file, mode = 'w', encoding = 'utf-8', newline = '') as f:\n",
    "    col_names = ['job_title', 'ad_date', 'ad_id', 'ad_type', 'job_type', 'job_duration', 'job_wage', 'app_link', 'app_email', 'location', 'contact', 'job_descrip', 'job_profile', 'link']\n",
    "    writer = csv.DictWriter(f, fieldnames = col_names)\n",
    "    writer.writeheader()\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe5a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
