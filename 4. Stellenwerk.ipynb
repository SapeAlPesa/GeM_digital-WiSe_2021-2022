{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5c0cf6",
   "metadata": {},
   "source": [
    "# Webscraper für die Studentenjobs auf www.stellenwerk-hamburg.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac34fb7",
   "metadata": {},
   "source": [
    "## Installieren und importieren benötigter Bibliotheken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5bb5c",
   "metadata": {},
   "source": [
    "Die Python-Bibliotheken *requests*, *BeautifulSoup* und *tqdm* müssen vor der ersten Verwendung installiert werden. Mit *requests* ist es möglich, über Python HTTP-Anfragen zu stellen. Mit *BeautifulSoup* kann man HTML-Code parsen und mit *tqdm* kann man sich bei langwierigen Programmausführungen Fortschrittsbalken anzeigen lassen. Die Installation geht folgendermaßen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0905b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a2366",
   "metadata": {},
   "source": [
    "Die ebenfalls benötigten Bibliotheken *time* (zum Verzögern der Programmausführung) und *csv* (zum Arbeiten mit csv-Dateien) sind Teil von Python und müssen nicht extra installiert werden. Sie müssen aber importiert werden, damit man sie verwenden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4841f0a9",
   "metadata": {},
   "source": [
    "Alle benötigten Bibliotheken importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99867df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b85e5",
   "metadata": {},
   "source": [
    "## Anforderungen an den Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517a1cd",
   "metadata": {},
   "source": [
    "Die **Stellenanzeigen für Studentenjobs** auf den Seiten des Stellenwerks sind [hier](https://www.stellenwerk-hamburg.de/jobboerse/unternehmen/studentenjobs) zu finden.\n",
    "Die Seite ist so aufgebaut, dass immer 20 Stellenangebote auf einer Seite verlinkt werden. Um die nächsten 20 Links zu Stellenangebote zu sehen, muss weitergeblättert werden. Die eigentliche Information zur Stelle findet sich hinter dem jeweiligen Link. Um an die Informationen über die Stellenangebote zu gelangen, müssen entsprechend diese Job-spezifischen Links aufgerufen werden.\n",
    "Der Webscraper für das Stellenwerk muss somit\n",
    "- Webseite des Stellenwerks aufrufen\n",
    "- blättern und wissen, wie oft weitergeblättert werden muss (Seitenzahl)\n",
    "- die 20 Links je Seite auslesen\n",
    "- eine Liste aller (Seitenzahl x 20) Links zusammenstellen\n",
    "- alle so gewonnen Links zu den jeweiligen Stellenanzeigen aufrufen\n",
    "- die stellenbezogenen Informationen extrahieren\n",
    "- die extrahierten Informationen in einer CSV-Datei abspeichern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24106b",
   "metadata": {},
   "source": [
    "## Aufbau der URL des Stellenwerks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe44070",
   "metadata": {},
   "source": [
    "Wenn man durch die Seiten mit den Stellenanzeigen blättert, stellt man fest, dass die URL des Stellenwerks [*Query Strings*](https://de.wikipedia.org/wiki/Query-String) nutzt, um Parameter (insbesondere der Suchanfrage) an den Webserver zu senden. Die URLs haben folgenden beispielhaften Aufbau:\n",
    "\n",
    "https://www.stellenwerk-hamburg.de/jobboerse/unternehmen/studentenjobs?keywords=&offer_type=job_ad_b2b&job_category=111&employment_type=All&page=1\n",
    "\n",
    "Der Query-String wird mit einem Fragezeichen (?) eingeleitet und besteht aus einem oder mehreren Schlüssel=Wert-Paaren. Im Fall mehrerer Schlüssel=Wert-Paare sind diese mit einem & verbunden. Vor dem Query-String steht die Basis-URL. Somit läst sich der URL des Stellenwerks in folgende Bestandteile gliedern:\n",
    "\n",
    "- Basis-URL: https://www.stellenwerk-hamburg.de/jobboerse/unternehmen/studentenjobs\n",
    "- Query-String: [keywords=&offer_type=job_ad_b2b&job_category=111&employment_type=All&page=1](https://www.stellenwerk-hamburg.de/jobboerse/unternehmen/studentenjobs?keywords=&offer_type=job_ad_b2b&job_category=111&employment_type=All&page=1)<br>\n",
    "mit folgenden Schlüssel=Wert-Paaren:\n",
    "    - keywords=\n",
    "    - offer_type=job_ad_b2b\n",
    "    - job_category=111\n",
    "    - employment_type=All\n",
    "    - page=1\n",
    "\n",
    "Diese Schlüssel=Wert-Paare des Query Strings werden im Folgenden in einem [Python-Dictionary](https://www.w3schools.com/python/python_dictionaries.asp) mit den Namen *query* gespeichert. Das Python-Dictionary wird dann - neben der Basis-URL - an *requests* übergeben, um die Webseite aufzurufen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "289257cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.stellenwerk-hamburg.de/jobboerse/unternehmen/studentenjobs\"\n",
    "query = {\n",
    "    'keywords': '',\n",
    "    'offer_type': 'job_ad_b2b',\n",
    "    'job_category': '111',\n",
    "    'employment_type': 'All',\n",
    "    'page': '0'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf615dcf",
   "metadata": {},
   "source": [
    "## Wir tarnen uns als Firefox "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a0c19",
   "metadata": {},
   "source": [
    "Standardmäßig offenbart sich die *requests*-Bibliothek selbst, indem sie sich beim Aufrufen einer Webseite im *request header* als User-Agent nennt: **'User-Agent': 'python-requests/2.26.0'**.<br>\n",
    "Um nicht sofort als Web-Scraper aufzufallen, ändern wir den entsprechenden Eintrag im *request header* und geben uns als Firefox-Browser aus (die Angaben, die Firefox sendet, habe ich mit den *Werkzeugen für Webentwickler* im Firefox-Browser ermittelt über **Netzwerkanalyse** &rightarrow; **Kopfzeilen** &rightarrow; **Anfragekopfzeilen**). Dazu werden die Angaben, die Firefox sendet, in einem Python-Dictionary namens *my_headers* gespeichert, damit sie an *requests* übergeben werden können. Damit werden die ursprünglichen Angaben zum User-Agenten überschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b33bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ee31d",
   "metadata": {},
   "source": [
    "## Aufruf der Webseite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d5030",
   "metadata": {},
   "source": [
    "Nun wird ein *Get-Request* zum Aufruf der Stellenwerk-Webseite an den Webserver gestellt. Neben der Basis-URL müssen auch die Informationen aus dem Query String an *requests* übergeben werden. Dazu wird das oben erstellte Python-Dictionary mit dem Namen *query* dem funktionseigenen Argument *params* übergeben. Ebenso wird das Dictionary mit dem Namen *my_headers* dem funktionseigenen Argument *headers* übergeben, um uns so als Firefox-Browser zu tarnen.<br>\n",
    "Anfrage und die Antwort des Webservers werden von *requests* in einem sog. Response-Objekt gespeichert. Dieses Response-Objekt wird dann der [Variablen](https://www.w3schools.com/python/python_variables.asp) *r* zugewiesen, so dass wir im weiteren Verlauf damit arbeiten können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23ab1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(base_url, params = query, headers = my_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77f346a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stellenwerk-hamburg.de/jobboerse/unternehmen/studentenjobs?keywords=&offer_type=job_ad_b2b&job_category=111&employment_type=All&page=0\n"
     ]
    }
   ],
   "source": [
    "print(r.request.url) # aufgerufene URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed299034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "print(r.request.headers) # an den Webserver gesendete Anfragekopfezeile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dca152b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(r.status_code) # War der Webseitenaufruf erfolgreich?\n",
    "print(r.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5319c2a",
   "metadata": {},
   "source": [
    "## HTML-Code der Webseite speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54195edd",
   "metadata": {},
   "source": [
    "Nun wird mit `.text` der übermittelte HTML-Quellcode der Stellenwerk-Webseite als Unicode-Text aus dem Response-Objekt *r* extrahiert und in der Variable *html* gespeichert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ed87063",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83038bcd",
   "metadata": {},
   "source": [
    "Diese Variable wird als Input an *BeautifulSoup* übergeben und von *BeautifulSoup* in ein *BeautifulSoup*-Objekt umgewandelt. *BeautifulSoup*-Objekte erlauben es, durch den HTML-Quellcode zu navigieren, in diesem Code nach spezifischen Inhalten zu suchen und diese Inhalte zu extrahieren. Das *BeautifulSoup*-Objekt wird der Variable *bs* zugewiesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be089ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379dff8",
   "metadata": {},
   "source": [
    "## Gesuchte Informationen aus dem HTML-Code auslesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db076a",
   "metadata": {},
   "source": [
    "### Links zu den jeweiligen Stellenanzeigen auslesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c6d07",
   "metadata": {},
   "source": [
    "Aus dem Quellcode der Webseite wird das HTML-Element ausgelesen, in dem die Stellenanzeigen zu finden sind. Um dieses Element im Quellcode zu identifizieren, verwendet man die *Browserwerkzeuge* bzw. *Entwicklertools* des jeweiligen Browsers. Diese kann man in den meisten Browsern mit <kbd>Strg</kbd>+<kbd>UMSCHALTTASTE</kbd>+<kbd>I</kbd> öffnen. Hier wählt man dann den Reiter *Inspektor*.\n",
    "Wenn man nun die Maus über die Webseite bewegt, ändert sich das hervorgehobene Element. Gleichzeitig wird der dazugehörge HTML-Quellcode im Fensterbereich der *Browserwerkzeuge* angezeigt. Hier sind auch rudimentäre Kenntnisse von HTML und CSS hilfreich, um die entsprechenden Elemente im Quellcode zu bestimmen.<br>\n",
    "Die Informationen zu den ausgeschriebenen Jobs befinden sich in einem\n",
    "[*div*](https://www.w3schools.com/tags/tag_div.ASP)-Tag, welches mit einem CSS [*class*](https://www.w3schools.com/css/css_selectors.asp)-Selektor gestaltet wurde. In diesem Fall ist *class=\"JobSearch-content\"*. Mit diesen Informationen und der Funktion  `find()` von *BeautifulSoup* können die entsprechenden Informationen aus dem HTML-Quellcode extrahiert und in eine Variable *job_ads* gespeichert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8051937",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ads = bs.find('div', class_ = 'JobSearch-content')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a8a0ab",
   "metadata": {},
   "source": [
    "Aus diesem so extrahierten HTML-Element werden in einem weiteren Schritt alle Links zu den Stellenanzeigen ausgelesen. Links werden in HTML über einen [*a*](https://www.w3schools.com/tags/tag_a.asp)-Tag definiert. Die Links zu den Stellenanzeigen befinden sich in einem *a*-Tag mit dem CSS-Selektor *class=\"Link\"*. Da es hier mehrere entsprechende Elemente gibt, muss die Funktion `find_all()` von *BeautifulSoup* verwendet werden, um alle Links zu finden. Die so extrahierten Links werden in die Listen-Variable *job_links* geschrieben. Die URL, zu der der Link führt, befindet sich in dem *href*-Attribut des *a*-Tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2585e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_links = job_ads.find_all('a', class_ = 'Link')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21674f",
   "metadata": {},
   "source": [
    "Anzahl an Stellenanzeigen in der Liste *job_links*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d325b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dca624",
   "metadata": {},
   "source": [
    "Es befinden sich immer 20 Links zu den Stellenanzeigen auf jeder der Unterseiten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4257c19",
   "metadata": {},
   "source": [
    "Als nächstes werfen wir einen Blick auf die so extrahierten Links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf0c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jobboerse/werkstudent-innovations-wmd-hamburg-211110-502338\n",
      "/jobboerse/studentische-aushilfe-im-bereich-digital-hamburg-211110-502335\n",
      "/jobboerse/werkstudent-corporate-strategy-mwd-hamburg-211110-502333\n",
      "/jobboerse/buerohilfe-gesucht-hamburg-211110-502330\n",
      "/jobboerse/werkstudentin-operations-management-produktion-nivea-deosprays-mwd-hamburg-211110-502329\n",
      "/jobboerse/wir-suchen-unterstuetzung-fuer-unseren-vertriebkundenservice-braak-211110-502328\n",
      "/jobboerse/werkstudent-produktion-operations-labello-mwd-hamburg-211110-502327\n",
      "/jobboerse/werkstudent-material-management-mwd-hamburg-211110-502325\n",
      "/jobboerse/werkstudent-mwd-finance-und-controlling-hamburg-211026-499402\n",
      "/jobboerse/werkstudent-process-development-mwd-hamburg-211110-502320\n",
      "/jobboerse/werkstudent-mwd-it-erp-production-hamburg-211026-499398\n",
      "/jobboerse/werkstudentin-fuer-unser-family-officevermoegenscontrolling-hamburg-hamburg-211026-499381\n",
      "/jobboerse/werkstudent-procurement-marketing-services-mwd-hamburg-211110-502307\n",
      "/jobboerse/mitarbeiter-poke-bowl-zubereitungverkauf-mwd-auf-450-eu-basis-hamburg-211110-502304\n",
      "/jobboerse/werkstudent-mwd-produktdatenteam-hamburg-211110-502302\n",
      "/jobboerse/werkstudent-projektbezogen-fuer-die-zeichnungserstellung-mwd-hamburg-211110-502300\n",
      "/jobboerse/werkstudent-mwd-franzoesisch-hamburg-211110-502299\n",
      "/jobboerse/office-manager-wmd-teilzeit-hamburg-211110-502287\n",
      "/jobboerse/seminarbetreuung-vielseitiger-mini-job-am-campus-weiterbildung-der-haw-hamburg-hamburg\n",
      "/jobboerse/werkstudent-mwd-compliance-hamburg-211110-502259\n"
     ]
    }
   ],
   "source": [
    "for l in job_links:\n",
    "    print(l['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3f1f4",
   "metadata": {},
   "source": [
    "Wie man sieht, sind die Links unvollständig, da Protokoll (https://) und Hostname (www.stellenwerk-hamburg.de) fehlen. Die fehlenden Informationen werden den Links hinzugefügt und die nun vollständigen Links werden in der Listen-Variable *rows* gespeichert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98a6635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for link in job_links:\n",
    "    link = 'https://www.stellenwerk-hamburg.de' + link['href']\n",
    "    rows.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae255854",
   "metadata": {},
   "source": [
    "Jetzt sehen die Links so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a49680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stellenwerk-hamburg.de/jobboerse/aushilfe-werkstudent-unserem-lifestyle-bistro-mwd-eimsbuettel-hamburg-rotherbaum-211117\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/paedagogische-kraefte-mw-fuer-vorschulklassen-gesucht-hamburg-211018-497612\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/studentische-mitarbeiter-mwdiv-im-kaufmaennischen-bereich-id-11-21-016-hamburg-211117\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudent-qualitaetskontrolle-wmd-hamburg-211117-503577\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/dozenten-mwd-gesucht-psychologie-lernstrategien-5hwoche-hamburg-211117-503576\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/nachhilfelehrer-mwd-hamburg-211117-503575\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/theater-kunst-sport-musik-alltag-hamburg-211117-503573\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudent-jura-mwd-hamburg-211117-503572\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudentin-research-analyst-mwd-hamburg-211117-503569\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudent-mwd-internes-startup-new-brand-billerbeck-211117-503556\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/video-und-foto-produktion-social-media-als-werkstudent-mwd-hamburg-211018-497535\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudentischer-operation-managerin-mwd-hamburg-211117-503553\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/praxisassistenz-neurologisch-psychiatrischer-praxis-praeventionszentrum-hamburg-211102\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/studentische-aushilfen-hamburg-211116-503542\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudent-mwd-it-prozesse-hamburg-211116-503541\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/studenten-lehrkraefte-zur-erteilung-von-nachhilfe-zu-hause-gesucht-deutschland-211116\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/kita-hoppetosse-sucht-ab-sofort-paedagogische-aushilfe-auf-honorarbasis-hamburg-211116\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudent-im-bereich-personalmarketing-kommunikation-mwd-hamburg-211116-503524\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudent-mwd-fuer-die-abteilung-digitales-lernen-hamburg-211116-503523\n",
      "https://www.stellenwerk-hamburg.de/jobboerse/werkstudent-zur-unterstuetzung-der-product-owner-edeka-apps-mwd-hamburg-211116-503522\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892d6d8",
   "metadata": {},
   "source": [
    "# Blättern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad0f20",
   "metadata": {},
   "source": [
    "Die Stellenanzeigen sind über mehrere Seiten à 20 Links verteilt. Wir müssen also blättern, um an alle Links zu kommen. Wie oft geblättert werden muss, kann man der Seite im unteren Bereich entnehmen.<br>\n",
    "Die Information zur Anzahl der Seiten befindet sich in einem [*span*](https://www.w3schools.com/tags/tag_span.asp)-Tag mit dem CSS-Selektor *class=\"Pagination-text\"*. Mit der Funktion  `find()` von *BeautifulSoup* kann die Informationen aus dem HTML-Quellcode extrahiert werden. Mit der Funktion `.get_text()` wird die so extrahierte Information in Text umgewandelt (andernfalls wäre sie ein *BeautifulSoup*-Objekt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1473158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seite 1 von 55\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "pages = bs.find('span', class_ = 'Pagination-text').get_text()\n",
    "print(pages)\n",
    "print(type(pages)) # Abfrage des Datentyps; hier: string (Zeichenkette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae077925",
   "metadata": {},
   "source": [
    "Aus diesem String kann man die maximale Seitenzahl folgendermaßen isolieren. Der String wird über die Methode `.split()` am Leerzeichen (' ') in seine Komponenten zerlegt. Aus der Liste der Komponenten wird dann das vierte Element extrahiert. Das vierte Element hat den Index 3, da die Indexzählung bei 0 beginnt. Schließlich wird der String mit `int()` in ein Integer (ganzzahliger Wert) umgewandelt und ist somit numerisch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a35884",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_max = int(pages.split(' ')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f51b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(page_max)\n",
    "print(type(page_max)) # Abfrage des Datentyps; hier: integer (ganzzahliger Wert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a968c",
   "metadata": {},
   "source": [
    "Nun kann diese Information genutzt werden, um zu blättern. Dazu wird eine for-Schleife in Kombination mit der Funktion `range()` verwendet. `range()` bestimmt, wie häufig die Schleife durchlaufen wird. Hier setzen wir *page_max* ein und addieren eine Eins hinzu, da `range()` standardmäßig bei Null starten und den Stoppwert nicht mit einschließen würde. In jedem Schleifendurchlauf wird im *query string* der Wert für den Schlüssel *page* (s. oben unter Aufbau der URL des Stellenwerks) um eins erhöht. Im ersten Durchlauf ist page=1, im zweiten page=2, im dritten page=3 usw. Alle Links zu den Stellenanzeigen, die auf einer Seite zu finden sind, werden dann extrahiert und zu der Liste *all_links* hinzugefügt.<br>\n",
    "Nach jedem Schleifendurchlauf stoppen wir mit `time.sleep(2)` das Programm für 2 Sekunden, bevor wir die nächste Seite aufrufen. Andernfalls würden wir mit zu vielen Anfragen in kurzer Zeit eventuell den Server überlasten. Dies würde schlimmstenfalls eine [Denial-of-Service-Attacke](https://www.bsi.bund.de/DE/Themen/Verbraucherinnen-und-Verbraucher/Cyber-Sicherheitslage/Methoden-der-Cyber-Kriminalitaet/DoS-Denial-of-Service/dos-denial-of-service_node.html) darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4c26ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b143030d3a1241ff861d008e5e893abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-7a20ef78c7e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.stellenwerk-hamburg.de'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mall_links\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Links der Link-Liste hinzufügen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# zwei Sekunden Verzögerung nach jedem Seitenaufruf: friendly scraping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_links = [] # Anlegen einer leeren Liste zur Aufnahme der Links\n",
    "for page in tqdm(range(page_max + 1)): # tqdm vor range erzeugt einen Fortschrittsbalken \n",
    "    query[\"page\"] = page # Seitenzahl wird in jedem Schleifendurchlauf um 1 erhöht\n",
    "    r = requests.get(base_url, params = query) # Webseite aufrufen\n",
    "    html = r.text # HTML-Code der Webseite speichern\n",
    "    bs = BeautifulSoup(html, 'html.parser') # HTML-Code an BeautifulSoup übergeben\n",
    "    job_ads = bs.find('div', class_ = 'JobSearch-content') # Spalte mit den Stellenanzeigen extrahieren\n",
    "    job_links = job_ads.find_all('a', class_ = 'Link') # aus dieser Spalte die Links zu den Anzeigen extrahieren\n",
    "    for link in job_links: # Protokoll und Hostname jedem Link vorangestellen\n",
    "        link = 'https://www.stellenwerk-hamburg.de' + link['href']\n",
    "        all_links.append(link) # Links der Link-Liste hinzufügen\n",
    "    time.sleep(2) # zwei Sekunden Verzögerung nach jedem Seitenaufruf: friendly scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9bd18",
   "metadata": {},
   "source": [
    "Wie viele Elemente hat die Liste *all_links* nach dem durch alle Seiten geblättert wurde? Diese Anzahl entspricht der Anzahl an Stellenangeboten zum Scraping-Zeitpunkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95bdb082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n"
     ]
    }
   ],
   "source": [
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0dbbb4",
   "metadata": {},
   "source": [
    "Nun liegt eine Liste mit allen Links zu den Stellenangeboten vor. Jetzt muss noch bestimmt werden, welche Informationen zu den jeweiligen Stellenangeboten extrahiert werden sollen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97738b",
   "metadata": {},
   "source": [
    "### Anzeige-Informationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "efd27370",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = bs.find('h1', class_ = 'JobHead-title').get_text()\n",
    "ad_date = bs.find('li', class_ = 'JobHead-additionalInfoItem').get_text().split(' ')[2]\n",
    "ad_id = bs.select('li.JobHead-additionalInfoItem:nth-child(2)')[0].get_text()\n",
    "ad_type = bs.select('li.JobHead-additionalInfoItem:nth-child(3)')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d5d7b",
   "metadata": {},
   "source": [
    "Mit Hilfe einer For-Schleife kann jeder Link aufgerufen und die relevanten Informationen zu den Stellenanzeigen extrahiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a2e6ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee5f4144a594f25994a0b20f389f7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for link in tqdm(all_links): # tqdm vor der iterierbaren Liste 'all_links' erzeugt einen Fortschrittsbalken \n",
    "    r = requests.get(link, headers = my_headers)\n",
    "    html = r.text\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        job_title = bs.find('h1', class_ = 'JobHead-title').get_text()\n",
    "    except:\n",
    "        job_title = None\n",
    "    try:\n",
    "        ad_date = bs.find('li', class_ = 'JobHead-additionalInfoItem').get_text().split(' ')[2]\n",
    "    except:\n",
    "        ad_date = None\n",
    "    try:    \n",
    "        ad_id = bs.select('li.JobHead-additionalInfoItem:nth-child(2)')[0].get_text()\n",
    "    except:\n",
    "        ad_id = None\n",
    "    try:\n",
    "        ad_type = bs.select('li.JobHead-additionalInfoItem:nth-child(3)')[0].get_text()\n",
    "    except:\n",
    "        ad_type = None\n",
    "    try:\n",
    "        job_type = bs.find(string = \"Art der Beschäftigung\").find_next('dd').get_text() # Suche nach dem Tag mit Inhalt \"Art der Beschäftigung\", dann das folgende dd-Tag wählen\n",
    "    except:\n",
    "        job_type = None\n",
    "    try:\n",
    "        job_duration = bs.find(string = \"Zeitraum der Beschäftigung\").find_next('dd').get_text()\n",
    "    except:\n",
    "        job_duration = None\n",
    "    try:\n",
    "        job_wage = bs.find(string = \"Vergütung\").find_next('dd').get_text()\n",
    "    except:\n",
    "        job_wage = None\n",
    "    try:\n",
    "        app_link = bs.find(string = \"Bewerbungslink\").find_next('dd').find_next('a', class_ = 'Link')['href']\n",
    "    except:\n",
    "        app_link = None\n",
    "    try:\n",
    "        app_email = bs.find(string = \"Bewerbungs-E-Mail\").find_next('a', class_ = 'IconText-mail IconText')['href']\n",
    "    except:\n",
    "        app_email = None\n",
    "    try:\n",
    "        company = bs.find(string = \"Firmenname\").find_next('dd').get_text()\n",
    "    except:\n",
    "        company = None\n",
    "    try:\n",
    "        loc = bs.find(string = \"Standort\").find_all_next('dd', limit = 2)\n",
    "        location = loc[0].get_text()+ \", \" + loc[1].get_text()\n",
    "    except:\n",
    "        loc, location = None, None\n",
    "    try:\n",
    "        contact = bs.find(string = \"Kontaktperson\").find_next('dd').get_text()\n",
    "    except:\n",
    "        contact = None\n",
    "    try:\n",
    "        job_descrip = bs.find_all('div', class_ = 'RichText')[0].get_text()\n",
    "    except:\n",
    "        job_descrip = None\n",
    "    try:\n",
    "        job_profile = bs.find_all('div', class_ = 'RichText')[1].get_text()\n",
    "    except:\n",
    "        job_profile = None\n",
    "    row = {\n",
    "    'job_title': job_title,\n",
    "    'ad_date': ad_date,\n",
    "    'ad_id': ad_id,\n",
    "    'ad_type': ad_type,\n",
    "    'job_type': job_type,\n",
    "    'job_duration': job_duration,\n",
    "    'job_wage': job_wage,\n",
    "    'app_link': app_link,\n",
    "    'app_email': app_email,\n",
    "    'company': company,\n",
    "    'location': location,\n",
    "    'contact': contact,\n",
    "    'job_descrip': job_descrip,\n",
    "    'job_profile': job_profile,\n",
    "    'link': link\n",
    "    }\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a6f49",
   "metadata": {},
   "source": [
    "## Stellen-Informationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "76b8c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type = bs.find(string = \"Art der Beschäftigung\").find_next('dd').get_text() # Suche nach dem Tag mit Inhalt \"Art der Beschäftigung\", dann das folgende dd-Tag wählen\n",
    "job_duration = bs.find(string = \"Zeitraum der Beschäftigung\").find_next('dd').get_text()\n",
    "try:\n",
    "    job_wage = bs.find(string = \"Vergütung\").find_next('dd').get_text()\n",
    "except:\n",
    "    job_wage = None\n",
    "try:\n",
    "    app_link = bs.find(string = \"Bewerbungslink\").find_next('dd').find_next('a', class_ = 'Link')['href']\n",
    "except:\n",
    "    app_link = None\n",
    "try:\n",
    "    app_email = bs.find(string = \"Bewerbungs-E-Mail\").find_next('a', class_ = 'IconText-mail IconText')['href']\n",
    "except:\n",
    "    app_email = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba6967",
   "metadata": {},
   "source": [
    "## Firmen-Informationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "17b60652",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = bs.find(string = \"Firmenname\").find_next('dd').get_text()\n",
    "loc = bs.find(string = \"Standort\").find_all_next('dd', limit = 2)\n",
    "location = loc[0].get_text()+ \", \" + loc[1].get_text()\n",
    "contact = bs.find(string = \"Kontaktperson\").find_next('dd').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9bf3d",
   "metadata": {},
   "source": [
    "## Beschreibung der Stelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "853d6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descrip = bs.find_all('div', class_ = 'RichText')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40db65",
   "metadata": {},
   "source": [
    "## Anforderungsprofil der Stelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ea9ec05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profile = bs.find_all('div', class_ = 'RichText')[1].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bef10",
   "metadata": {},
   "source": [
    "## Extrahierte Daten in eine CSV-Datei schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8b5f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'daten/job_ads.csv'\n",
    "with open(file, mode = 'w', encoding = 'utf-8', newline = '') as f:\n",
    "    col_names = ['link', 'job_title', 'ad_date', 'ad_id', 'ad_type', 'job_type', 'job_duration', 'job_wage', 'app_link', 'app_email', 'company', 'location', 'contact', 'job_descrip', 'job_profile', 'link']\n",
    "    writer = csv.DictWriter(f, fieldnames = col_names)\n",
    "    writer.writeheader()\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f68fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
